1. Why Theory is Dead: Anderson

Chris Anderson argues that with the sudden abundance of data today, models are no longer valuable. Models that were once useful when society did not have access to whole data sets, sought to collapse data into graphic summaries revealing a trend or lack thereof. Anderson labels this age of data as the “Petabyte Age” as society shifts towards more accessible and exhaustive data. This age marked by a stark increase in data allows all data analysts to substitute the traditional strategy of sifting through data searching for patterns that support their hypotheses, and instead collect data and seek trends revealed by the data set. This method neglects any biases the analysts previously held and allows the data to influence the findings, conclusions, and explanations.
	
Not only do models fall victim to initial biases, but they also hold an innate emphasis on the “why” of the data. Models promote a trend-seeking analysis instead of looking at the data mathematically and objectively. In the Petabyte Age, the “why” no longer matters, because we have the “what,” being, the data itself- not a mere reductive representation of it. This completely reinvents the concept that correlation does not prove causation. Today, we already have access to the data that allows us to fully understand the connection between the correlation, the causation, and how they work together. The condensed nature of models make them insufficient and misleading without exhaustive datasets to supplement them. Data sets are practical on their own, models however, cannot effectively stand alone. Even when models are backed by data sets, they fail to inspire a wholistic and contextualized perspective, making them essentially useless in our modern Petabyte Age.

2. Data-Driven Approach: Kitchin
	Rob Kitchin asserts that the data-driven approach to a new epistemology makes a better argument than the recently appreciated empiricist view that tends to attractively oversimplify the complexity of Big Data to hyperbolize its convenience. The data-driven approach however, values the exhaustivity, subjectivity, and variety of big data, and argues that data science technology can combat the very issues that arise from the expansive and complex nature of big data. For example, machine learning and artificial intelligence can detect patterns and employ predictive analytics to optimize results in business, learning, and even politics.
Society can use data to pull out valuable pieces of information that can then be displayed in extensive models that are reflexive and holistic. These models can exclusively display what is meaningful to the specific project, rather than displaying huge amounts of data and expecting the audience to decipher what pieces are relevant to the central question. Not only do models help streamline our focus when interpreting data sets, but the models themselves can be improved due to the sheer abundance of data and technology. Models can be easily updated and reflective of new pieces of information. If the focus in a research project shifts due to a discovery in the data sight, models can visually outline the particular insight in the dataset that influenced the central focus in an easy to understand manner.
